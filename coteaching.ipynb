{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToTensor\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Architecture and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "from model import CNN\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from utils import EarlyStopping\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def co_teaching_loss(model1_loss, model2_loss, rt):\n",
        "    _, model1_sm_idx = torch.topk(model1_loss, k=int(int(model1_loss.size(0)) * rt), largest=False)\n",
        "    _, model2_sm_idx = torch.topk(model2_loss, k=int(int(model2_loss.size(0)) * rt), largest=False)\n",
        "\n",
        "    # Co-teaching\n",
        "    model1_loss_filter = torch.zeros((model1_loss.size(0))).cuda()\n",
        "    model1_loss_filter[model2_sm_idx] = 1.0\n",
        "    model1_loss = (model1_loss_filter * model1_loss).sum()\n",
        "\n",
        "    model2_loss_filter = torch.zeros((model2_loss.size(0))).cuda()\n",
        "    model2_loss_filter[model1_sm_idx] = 1.0\n",
        "    model2_loss = (model2_loss_filter * model2_loss).sum()\n",
        "\n",
        "    return model1_loss, model2_loss\n",
        "\n",
        "\n",
        "def train_step(data_loader, gpu: bool, model_list: list, optimizer, criterion, rt, warmups):\n",
        "    global_step = 0\n",
        "    avg_accuracy = 0.\n",
        "    avg_loss = 0.\n",
        "\n",
        "    model1, model2 = model_list\n",
        "    model1 = model1.train()\n",
        "    model2 = model2.train()\n",
        "    for x, y in data_loader:\n",
        "        # Forward and Backward propagation\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        out1 = model1(x)\n",
        "        out2 = model2(x)\n",
        "\n",
        "        out2_pred = torch.argmax(out2, 1)\n",
        "        out1_pred = torch.argmax(out1, 1)\n",
        "\n",
        "        if warmups > 0:\n",
        "            model1_loss = criterion(out1, y)\n",
        "            model2_loss = criterion(out2, y)\n",
        "            model1_loss, model2_loss = co_teaching_loss(model1_loss=model1_loss, model2_loss=model2_loss, rt=rt)\n",
        "\n",
        "        elif warmups == 0:\n",
        "            model1_loss = criterion(out1, y)\n",
        "            model2_loss = criterion(out2, y)\n",
        "            model1_loss, model2_loss = co_teaching_loss(model1_loss=model1_loss, model2_loss=model2_loss, rt=rt)\n",
        "            model1_loss_pred = criterion(out1, out2_pred)\n",
        "            model2_loss_pred = criterion(out2, out1_pred)\n",
        "\n",
        "            model1_loss_label = criterion(out1, y)\n",
        "            model2_loss_label = criterion(out2, y)\n",
        "\n",
        "            model1_loss = 1 * model1_loss_pred + .0 * model1_loss_label\n",
        "            model2_loss = 1 * model2_loss_pred + .0 * model2_loss_label\n",
        "            model1_loss, model2_loss = co_teaching_loss(model1_loss=model1_loss, model2_loss=model2_loss, rt=rt)\n",
        "\n",
        "        # loss exchange\n",
        "        optimizer.zero_grad()\n",
        "        model1_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model1.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        model2_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model2.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_loss += (model1_loss.item() + model2_loss.item())\n",
        "\n",
        "        # Compute accuracy\n",
        "        acc = torch.eq(torch.argmax(out1, 1), y).float()\n",
        "        avg_accuracy += acc.mean()\n",
        "        global_step += 1\n",
        "\n",
        "    return avg_accuracy / global_step, avg_loss / global_step, [model1, model2]\n",
        "\n",
        "\n",
        "def test_step(data_loader, gpu: bool, model):\n",
        "    model = model.eval()\n",
        "    global_step = 0\n",
        "    avg_accuracy = 0.\n",
        "    predicted_labels = []\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        acc = torch.eq(torch.argmax(logits, 1), y)\n",
        "        acc = acc.cpu().numpy()\n",
        "        acc = np.mean(acc)\n",
        "        avg_accuracy += acc\n",
        "        global_step += 1\n",
        "        predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "    return avg_accuracy / global_step, predicted_labels\n",
        "\n",
        "\n",
        "def valid_step(data_loader, gpu: bool, model):\n",
        "    model = model.eval()\n",
        "    global_step = 0\n",
        "    avg_accuracy = 0.\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        logits = model(x)\n",
        "        acc = torch.eq(torch.argmax(logits, 1), y)\n",
        "        acc = acc.cpu().numpy()\n",
        "        acc = np.mean(acc)\n",
        "        avg_accuracy += acc\n",
        "        global_step += 1\n",
        "    return avg_accuracy / global_step\n",
        "\n",
        "\n",
        "def update_reduce_step(cur_step1, num_gradual, tau):\n",
        "    return 1.0 - tau * min(cur_step1 / num_gradual, 1)\n",
        "\n",
        "\n",
        "def train(lr, tau, num_gradual, warmups, gpu = True, epochs = 10):\n",
        "    model1 = CNN(3, 100)\n",
        "    model2 = CNN(3, 100)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "        model1 = nn.DataParallel(model1)\n",
        "        model2 = nn.DataParallel(model2)\n",
        "\n",
        "    model1.to(device)\n",
        "    model2.to(device)\n",
        "\n",
        "    # learning history\n",
        "    train_acc_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduce=False, label_smoothing=0.2)\n",
        "    optimizer = optim.Adam(chain(model1.parameters(), model2.parameters()), lr, weight_decay=1e-3)\n",
        "    for e in range(epochs):\n",
        "        # update reduce step\n",
        "        curstep1 = e\n",
        "        rt = update_reduce_step(curstep1, num_gradual, tau)\n",
        "\n",
        "        # training step\n",
        "        train_accuracy, avg_loss, model_list = train_step(data_loader=trainLoader,\n",
        "                                                          gpu=gpu,\n",
        "                                                          model_list=[model1, model2],\n",
        "                                                          optimizer=optimizer,\n",
        "                                                          criterion=criterion,\n",
        "                                                          rt=rt,\n",
        "                                                          warmups=warmups)\n",
        "        model1, model2 = model_list\n",
        "\n",
        "        if warmups > 0:\n",
        "            warmups = warmups - 1\n",
        "\n",
        "        # testing/valid step\n",
        "        test_accuracy, predicted_labels = test_step(data_loader=testLoader,\n",
        "                                  gpu=gpu,\n",
        "                                  model=model1)\n",
        "\n",
        "        dev_accuracy = valid_step(data_loader=valLoader,\n",
        "                                  gpu=gpu,\n",
        "                                  model=model1)\n",
        "\n",
        "        train_accuracy = train_accuracy.cpu().data.numpy()\n",
        "        train_acc_list.append(train_accuracy)\n",
        "        test_acc_list.append(test_accuracy)\n",
        "\n",
        "        # logging.info(\n",
        "        #     '{} epoch, Train Loss {}, Train accuracy {}, Dev accuracy {}, Test accuracy {}, Reduce rate {}'.format(e + 1,\n",
        "        #                                                                                                         avg_loss,\n",
        "        #                                                                                                         train_accuracy,\n",
        "        #                                                                                                         dev_accuracy,\n",
        "        #                                                                                                         test_accuracy,\n",
        "        #                                                                                                         rt))\n",
        "\n",
        "        # early_stopping(-dev_accuracy, model1, test_acc=test_accuracy)\n",
        "        # if early_stopping.early_stop:\n",
        "        #     logging.info('Training stopped! Best accuracy = {}'.format(max(early_stopping.acc_list)))\n",
        "        #     break\n",
        "\n",
        "    # learning curve plot\n",
        "    return train_acc_list, test_acc_list, epochs, predicted_labels"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datasets\n",
        "from torchvision.transforms import ToTensor as toTensor\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "    # Using previous information, skipping manual calculation\n",
        "])\n",
        "\n",
        "target_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainDataset = datasets.C100Dataset('dataset/data/cifar100_nl.csv', \n",
        "                                    root_dir=\"dataset\",\n",
        "                                    train=True,\n",
        "                                    transform= transform)\n",
        "\n",
        "testDataset = datasets.C100Dataset('dataset/data/cifar100_nl_test.csv',\n",
        "                                    root_dir=\"dataset\",\n",
        "                                    test=True,\n",
        "                                    transform = transform,\n",
        "                                    target_transform=target_transform)\n",
        "\n",
        "trainDataset, valDataset = random_split(trainDataset, [.8, .2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jubble/Library/Python/3.9/lib/python/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m valLoader \u001b[39m=\u001b[39m DataLoader(valDataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m testLoader \u001b[39m=\u001b[39m DataLoader(testDataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m train_acc_list, test_acc_list, epochs, predicted_labels \u001b[39m=\u001b[39m train(lr, tau, warmups, num_gradual, gpu, epochs)\n\u001b[1;32m     16\u001b[0m \u001b[39m#Set warmups to 0 to only use prediction co-teaching \u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(train_acc_list)\n",
            "Cell \u001b[0;32mIn[5], line 158\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(lr, tau, num_gradual, warmups, gpu, epochs)\u001b[0m\n\u001b[1;32m    155\u001b[0m rt \u001b[39m=\u001b[39m update_reduce_step(curstep1, num_gradual, tau)\n\u001b[1;32m    157\u001b[0m \u001b[39m# training step\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m train_accuracy, avg_loss, model_list \u001b[39m=\u001b[39m train_step(data_loader\u001b[39m=\u001b[39;49mtrainLoader,\n\u001b[1;32m    159\u001b[0m                                                   gpu\u001b[39m=\u001b[39;49mgpu,\n\u001b[1;32m    160\u001b[0m                                                   model_list\u001b[39m=\u001b[39;49m[model1, model2],\n\u001b[1;32m    161\u001b[0m                                                   optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    162\u001b[0m                                                   criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m    163\u001b[0m                                                   rt\u001b[39m=\u001b[39;49mrt,\n\u001b[1;32m    164\u001b[0m                                                   warmups\u001b[39m=\u001b[39;49mwarmups)\n\u001b[1;32m    165\u001b[0m model1, model2 \u001b[39m=\u001b[39m model_list\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m warmups \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
            "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(data_loader, gpu, model_list, optimizer, criterion, rt, warmups)\u001b[0m\n\u001b[1;32m     53\u001b[0m     model1_loss \u001b[39m=\u001b[39m criterion(out1, y)\n\u001b[1;32m     54\u001b[0m     model2_loss \u001b[39m=\u001b[39m criterion(out2, y)\n\u001b[0;32m---> 55\u001b[0m     model1_loss, model2_loss \u001b[39m=\u001b[39m co_teaching_loss(model1_loss\u001b[39m=\u001b[39;49mmodel1_loss, model2_loss\u001b[39m=\u001b[39;49mmodel2_loss, rt\u001b[39m=\u001b[39;49mrt)\n\u001b[1;32m     57\u001b[0m \u001b[39melif\u001b[39;00m warmups \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     58\u001b[0m     model1_loss \u001b[39m=\u001b[39m criterion(out1, y)\n",
            "Cell \u001b[0;32mIn[5], line 23\u001b[0m, in \u001b[0;36mco_teaching_loss\u001b[0;34m(model1_loss, model2_loss, rt)\u001b[0m\n\u001b[1;32m     20\u001b[0m _, model2_sm_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(model2_loss, k\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(\u001b[39mint\u001b[39m(model2_loss\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)) \u001b[39m*\u001b[39m rt), largest\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Co-teaching\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m model1_loss_filter \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros((model1_loss\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m)))\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     24\u001b[0m model1_loss_filter[model2_sm_idx] \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m     25\u001b[0m model1_loss \u001b[39m=\u001b[39m (model1_loss_filter \u001b[39m*\u001b[39m model1_loss)\u001b[39m.\u001b[39msum()\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "# Set parameters\n",
        "lr = 0.001\n",
        "tau = 0.3\n",
        "warmups = 50\n",
        "num_gradual = 30\n",
        "gpu = True\n",
        "epochs = 30\n",
        "batch_size = 128\n",
        "\n",
        "# Load loaders\n",
        "trainLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
        "valLoader = DataLoader(valDataset, batch_size=batch_size, shuffle=True)\n",
        "testLoader = DataLoader(testDataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training run\n",
        "\n",
        "train_acc_list, test_acc_list, epochs, predicted_labels = train(lr, tau, warmups, num_gradual, gpu, epochs)\n",
        "\n",
        "print(train_acc_list)\n",
        "\n",
        "\n",
        "xrange = [(i + 1) for i in range(epochs)]\n",
        "plt.plot(xrange, train_acc_list, 'b', label='Training accuracy')\n",
        "plt.plot(xrange, test_acc_list, 'r', label='Test accuracy')\n",
        "plt.legend()\n",
        "plt.title('Learning Curve')\n",
        "plt.savefig('l_curve.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xrange = [(i + 1) for i in range(epochs)]\n",
        "plt.plot(xrange, train_acc_list, 'b', label='training accuracy')\n",
        "plt.plot(xrange, test_acc_list, 'r', label='test accuracy')\n",
        "plt.legend()\n",
        "plt.title('Learning curve')\n",
        "plt.savefig('l_curve.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyONnvKUvE8P3fcGNKeCKeTR",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
